{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Boas pr√°ticas para a cria√ß√£o de prompts\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Execute no Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Vis√£o geral\n",
    "\n",
    "Este notebook aborda os fundamentos de design de prompts, incluindo algumas pr√°ticas recomendadas.\n",
    "\n",
    "Saiba mais sobre o design de prompt na [documenta√ß√£o oficial](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objetivo\n",
    "\n",
    "Neste notebook, voc√™ aprender√° as pr√°ticas recomendadas sobre o design de prompts -- como projetar prompts para melhorar a qualidade de suas respostas.\n",
    "\n",
    "Este notebook abrange as seguintes pr√°ticas recomendadas para engenharia imediata:\n",
    "\n",
    "- Ser conciso\n",
    "- Seja espec√≠fico e com um texto bem definido\n",
    "- Pe√ßa uma tarefa de cada vez\n",
    "- Transforme tarefas generativas em tarefas de classifica√ß√£o\n",
    "- Melhore a qualidade da resposta incluindo exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea013f50403c"
   },
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "\n",
    "Saiba mais sobre poss√≠veis custos envolvidos [pre√ßos da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "e use a [Calculadora de pre√ßos](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e663cb43fa0"
   },
   "source": [
    "### Instalando os SDK da Vertex AI e da Cloud Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "82ad0c445061",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cebd6983cbad"
   },
   "source": [
    "**Somente Colab:** Descomente a c√©lula a seguir para reiniciar o kernel ou use o bot√£o para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bea801acf6b5"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel ap√≥s as instala√ß√µes para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a386d25fa8f"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se voc√™ estiver usando o **Colab** para executar este notebook, descomente a c√©lula abaixo e continue.\n",
    "* Se voc√™ estiver usando o **Vertex AI Workbench**, confira as instru√ß√µes de configura√ß√£o [aqui](../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1bd1dca8e9a7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Importando as bibliotecas necess√°rias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a c√©lula a seguir para realizar o processo adequado de inicializa√ß√£o da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[seu-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "#### Carregando o modelo `text-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPcn5dZ7O-b"
   },
   "source": [
    "## Boas pr√°ticas de design de prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df7d153f4928"
   },
   "source": [
    "A engenharia de prompt trata de como projetar seus prompts para que a resposta seja o que voc√™ realmente esperava ver.\n",
    "\n",
    "A ideia de usar prompts \"desagrad√°veis\" √© minimizar o ru√≠do em seu prompt para reduzir a possibilidade de o LLM interpretar mal a inten√ß√£o do prompt. Abaixo est√£o algumas diretrizes sobre como projetar prompts \"desagrad√°veis\".\n",
    "\n",
    "Nesta se√ß√£o, voc√™ abordar√° as seguintes pr√°ticas recomendadas quando a engenharia solicitar:\n",
    "\n",
    "* Ser conciso\n",
    "* Seja espec√≠fico e com texto bem definido\n",
    "* Pe√ßa uma tarefa de cada vez\n",
    "* Melhore a qualidade da resposta incluindo exemplos\n",
    "* Transforme tarefas generativas em tarefas de classifica√ß√£o para melhorar a seguran√ßa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43c1169ac435"
   },
   "source": [
    "### Seja conciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0f380f1620e"
   },
   "source": [
    "üõë N√£o recomendado. O prompt abaixo √© desnecessariamente detalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b6a1697c3603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Flores Secas**\n",
      "* **Flores Preservadas**\n",
      "* **Flores Eternas**\n",
      "* **Flores Intemporais**\n",
      "* **Flores Atemporais**\n",
      "* **Flores Inesquec√≠veis**\n",
      "* **Flores Eternizadas**\n",
      "* **Flores Para Sempre**\n",
      "* **Flores que Duram**\n",
      "* **Flores que N√£o Morrem**\n",
      "* **Flores que N√£o Envelhecem**\n",
      "* **Flores que N√£o Perdem a Cor**\n",
      "* **Flores que N√£o Perdem o Brilho**\n",
      "* **Flores que N√£o Perdem o Aroma**\n",
      "* **Flores que N√£o Perdem a Beleza**\n",
      "* **Flores que N√£o Perdem o Charme**\n",
      "* **Flores que N√£o Perdem o Toque**\n",
      "* **Flores que N√£o Perdem o Significado**\n",
      "* **Flores que N√£o Perdem o Valor**\n",
      "* **Flores que N√£o Perdem a Import√¢ncia**\n",
      "* **Flores que N√£o Perdem o Amor**\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Que nomes voc√™ acha que seriam interessantes para uma floricultura que se especializa mais em buqu√™s de flores secas do que frescas? Muit√≠ssimo brigado!\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2307f56a9b75"
   },
   "source": [
    "‚úÖ Recomendado. O prompt abaixo √© direto ao ponto e conciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fc666404f47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Flores Secas**\n",
      "* **Buqu√™s Secos**\n",
      "* **Flores Eternas**\n",
      "* **Flores Preservadas**\n",
      "* **Flores Desidratadas**\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Sugira cinco nomes para uma floricultura que vende buqu√™s de flores secas\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17f6c48bba91"
   },
   "source": [
    "### Seja espec√≠fico e escreva textos bem definidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "269b428e1563"
   },
   "source": [
    "Suponha que voc√™ queira pensar em maneiras criativas de descrever a Terra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6436ee2ff406"
   },
   "source": [
    "üõë N√£o recomendado. O prompt abaixo √© muito gen√©rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "261b7f6e94c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Terra √© o terceiro planeta do Sistema Solar, o √∫nico que se sabe ser habitado por seres vivos. √â um planeta rochoso com uma atmosfera respir√°vel e uma hidrosfera abundante. A Terra √© o maior dos quatro planetas tel√∫ricos do Sistema Solar, e √© o √∫nico com uma crosta oce√¢nica cont√≠nua. A Terra √© o √∫nico planeta conhecido que tem vida, e √© o √∫nico planeta que foi visitado por seres humanos.\n",
      "\n",
      "A Terra tem uma superf√≠cie din√¢mica, com placas tect√¥nicas que se movem constantemente. A atividade tect√¥nica √© respons√°vel pela forma√ß√£o de montanhas, vulc√µes e terremotos. A Terra tamb√©m tem uma atmosfera din√¢mica, que √© composta principalmente de nitrog√™nio e oxig√™nio. A atmosfera protege a Terra da radia√ß√£o solar nociva e ajuda a manter a temperatura do planeta em um n√≠vel adequado para a vida.\n",
      "\n",
      "A Terra tem uma hidrosfera abundante, que √© composta de oceanos, mares, rios e lagos. A hidrosfera cobre cerca de 70% da superf√≠cie da Terra. A hidrosfera √© importante para a vida na Terra, pois fornece √°gua para beber, irriga√ß√£o e transporte. A hidrosfera tamb√©m ajuda a regular o clima da Terra.\n",
      "\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Fale-me sobre a Terra\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bebfecd2912"
   },
   "source": [
    "‚úÖ Recomendado. O prompt abaixo √© espec√≠fico e bem definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "242b1b3bae6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* A Terra √© o √∫nico planeta conhecido que abriga vida.\n",
      "* A Terra tem uma atmosfera rica em oxig√™nio, que √© essencial para a vida.\n",
      "* A Terra tem √°gua l√≠quida em sua superf√≠cie, que √© essencial para a vida.\n",
      "* A Terra tem uma temperatura adequada para a vida, nem muito quente nem muito fria.\n",
      "* A Terra tem um campo magn√©tico que protege a vida da radia√ß√£o solar.\n",
      "* A Terra tem um tamanho e uma massa adequados para a vida.\n",
      "* A Terra est√° localizada na zona habit√°vel do Sistema Solar, o que significa que est√° a uma dist√¢ncia adequada do Sol para permitir a exist√™ncia de √°gua l√≠quida na superf√≠cie.\n",
      "\n",
      "Esses s√£o apenas alguns dos motivos que tornam a Terra um planeta √∫nico e especial. √â um lugar onde a vida pode florescer e se desenvolver, e √© um lugar que devemos proteger.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Gere uma lista de motivos que fazem a Terra ser √∫nica comparada √† outros planetas\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20dca9a05eab"
   },
   "source": [
    "### Pe√ßa uma tarefa de cada vez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9019d443179"
   },
   "source": [
    "üõë N√£o recomendado. O prompt abaixo tem duas partes para a pergunta que pode ser feita separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "70b3b5e5825d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor forma de ferver √°gua √© usando uma panela com fundo grosso e tampa. Coloque a √°gua na panela e leve ao fogo m√©dio. Quando a √°gua come√ßar a ferver, reduza o fogo para baixo e deixe ferver por mais alguns minutos. Desligue o fogo e deixe a √°gua repousar por alguns minutos antes de usar.\n",
      "\n",
      "O c√©u √© azul porque a luz do Sol √© composta de v√°rias cores, incluindo o azul. Quando a luz do Sol atinge a atmosfera da Terra, as part√≠culas de ar espalham as cores da luz em todas as dire√ß√µes. As part√≠culas de ar espalham mais as cores da luz que t√™m comprimentos de onda mais curtos, como o azul. Por isso, vemos o c√©u azul.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Qual √© a melhor forma para ferver √°gua e por que o c√©u √© azul?\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7936fb58c16a"
   },
   "source": [
    "‚úÖ Recomendado. Os prompts abaixo solicitam uma tarefa por vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2564dad6c8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor forma para ferver √°gua √© usando uma chaleira el√©trica. As chaleiras el√©tricas s√£o seguras, eficientes e f√°ceis de usar. Elas tamb√©m s√£o mais r√°pidas do que ferver √°gua em uma panela no fog√£o.\n",
      "\n",
      "Para usar uma chaleira el√©trica, basta encher a chaleira com √°gua at√© a marca indicada e ligar o aparelho. A chaleira come√ßar√° a ferver a √°gua em poucos minutos. Quando a √°gua estiver fervendo, voc√™ ouvir√° um sinal sonoro. Voc√™ pode ent√£o desligar o aparelho e despejar a √°gua fervente em uma x√≠cara ou caneca.\n",
      "\n",
      "As chaleiras el√©tricas s√£o uma √≥tima op√ß√£o para quem quer ferver √°gua rapidamente e com seguran√ßa. Elas s√£o tamb√©m uma √≥tima op√ß√£o para quem quer economizar energia, pois s√£o mais eficientes do que ferver √°gua em uma panela no fog√£o.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Qual √© a melhor forma para ferver √°gua?\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "770c695ade92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O c√©u √© azul porque a luz do Sol √© espalhada pelas mol√©culas de ar na atmosfera. A luz do Sol √© composta de todas as cores do arco-√≠ris, mas as cores azuis s√£o espalhadas mais do que as outras cores. Isso porque as mol√©culas de ar s√£o menores do que as outras cores da luz do Sol, e elas interagem mais com as ondas de luz azuis. As outras cores da luz do Sol n√£o s√£o espalhadas tanto, ent√£o elas viajam para o nosso olho diretamente do Sol.\n",
      "\n",
      "A quantidade de espalhamento da luz azul depende da quantidade de mol√©culas de ar na atmosfera. Quando o ar est√° mais limpo, h√° menos mol√©culas de ar para espalhar a luz azul, ent√£o o c√©u parece mais azul. Quando o ar est√° mais polu√≠do, h√° mais mol√©culas de ar para espalhar a luz azul, ent√£o o c√©u parece mais cinza ou branco.\n",
      "\n",
      "O √¢ngulo do Sol tamb√©m afeta a cor do c√©u. Quando o Sol est√° baixo no horizonte, a luz do Sol tem que viajar atrav√©s de mais da atmosfera para chegar ao nosso olho. Isso significa que mais luz azul √© espalhada, ent√£o o c√©u parece mais azul. Quando o Sol est√° alto no c√©u, a luz do Sol n√£o tem que\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Por que o c√©u √© azul?\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff606011aa86"
   },
   "source": [
    "### Cuidado com as alucina√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "956ce45b06a7"
   },
   "source": [
    "Embora os LLMs tenham sido treinados em uma grande quantidade de dados, eles podem gerar textos contendo declara√ß√µes n√£o fundamentadas na verdade ou na realidade; essas respostas do LLM s√£o frequentemente chamadas de \"alucina√ß√µes\" devido √†s suas capacidades limitadas de memoriza√ß√£o. Observe que simplesmente solicitar que o LLM forne√ßa uma cita√ß√£o n√£o √© uma solu√ß√£o para esse problema, pois h√° inst√¢ncias de LLMs que fornecem cita√ß√µes falsas ou imprecisas. \n",
    "\n",
    "Lidar com alucina√ß√µes √© um desafio fundamental dos LLMs e uma √°rea de pesquisa em andamento, por isso √© importante estar ciente de que os LLMs podem parecer dar a voc√™ declara√ß√µes confiantes e corretas que, na verdade, s√£o incorretas.\n",
    "\n",
    "Observe que, se voc√™ pretende usar LLMs para os casos de uso criativo, alucinar pode ser bastante √∫til."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c9d5f66179a"
   },
   "source": [
    "Tente o prompt como o abaixo repetidamente. Voc√™ pode notar que √†s vezes ele dir√° com confian√ßa, mas imprecisamente, \"O primeiro elefante a visitar a lua foi Luna\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d813b9061b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O primeiro elefante a visitar a lua foi o elefante Babar. Babar foi um elefante criado pelo autor franc√™s Jean de Brunhoff. Babar foi criado em 1931 e apareceu em v√°rios livros e filmes. Babar √© um elefante muito inteligente e corajoso que sempre est√° pronto para ajudar os outros. Ele √© um grande amigo e um l√≠der s√°bio. Babar √© um personagem muito popular e tem sido amado por crian√ßas de todo o mundo por gera√ß√µes.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Quem foi o primeiro elefante a visitar a lua?\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "029e23abfd56"
   },
   "source": [
    "### Transforme tarefas generativas em tarefas de classifica√ß√£o para reduzir a variabilidade de sa√≠da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d943941d6e59"
   },
   "source": [
    "#### Tarefas generativas levam a uma maior variabilidade de sa√≠da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37528e6c9754"
   },
   "source": [
    "O prompt abaixo resulta em uma resposta aberta, √∫til para brainstorming, mas a resposta √© altamente vari√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "a8e2dc39e9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Fa√ßa projetos pessoais.** Um √≥timo jeito de aprender programa√ß√£o √© fazer projetos pessoais que voc√™ se interesse. Isso pode ser qualquer coisa, desde um jogo simples at√© um aplicativo para celular. Quando voc√™ est√° trabalhando em um projeto que voc√™ se importa, voc√™ √© mais propenso a ficar motivado e aprender mais.\n",
      "* **Leia artigos e livros sobre programa√ß√£o.** H√° muitos recursos dispon√≠veis online e na biblioteca que podem ajud√°-lo a aprender mais sobre programa√ß√£o. Leia artigos sobre t√≥picos que voc√™ est√° interessado, ou confira livros sobre programa√ß√£o que podem ajud√°-lo a desenvolver suas habilidades.\n",
      "* **Assista a v√≠deos sobre programa√ß√£o.** H√° muitos v√≠deos excelentes sobre programa√ß√£o dispon√≠veis no YouTube e em outros sites. Assistir a v√≠deos pode ser uma √≥tima maneira de aprender sobre novos conceitos e t√©cnicas de programa√ß√£o.\n",
      "* **Fa√ßa cursos online.** Existem muitos cursos online gratuitos e pagos que podem ajud√°-lo a aprender programa√ß√£o. Alguns dos cursos mais populares s√£o oferecidos pela Coursera, Udacity e edX.\n",
      "* **Participe de comunidades de programa√ß√£o.** Existem muitas comunidades online de programa√ß√£o onde voc√™ pode fazer perguntas, obter ajuda e compartilhar seus projetos. Algumas das comunidades mais populares s√£o Stack Overflow, Reddit e GitHub.\n",
      "* **\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Sou um estudante de ensino m√©dio. Recomende-me atividades de programa√ß√£o para melhorar meus skills\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f71a6fa2b4bb"
   },
   "source": [
    "#### Tarefas de classifica√ß√£o reduzem a variabilidade de sa√≠da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "917517465dac"
   },
   "source": [
    "O prompt abaixo resulta em uma escolha e pode ser √∫til se voc√™ quiser que a sa√≠da seja mais f√°cil de controlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3feb93d9df81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu recomendaria aprender Python. Python √© uma linguagem de programa√ß√£o de alto n√≠vel, interpretada, de uso geral, com sintaxe f√°cil de ler e aprender. √â uma linguagem multiparadigma, o que significa que pode ser usada para desenvolver programas de diferentes tipos, incluindo aplicativos de desktop, aplicativos m√≥veis, servidores web e sistemas de big data. Python √© tamb√©m uma linguagem muito popular, sendo usada por empresas como Google, Facebook, Amazon e Netflix.\n",
      "\n",
      "Javascript √© outra linguagem de programa√ß√£o popular, mas √© mais adequada para desenvolvimento web. Fortran √© uma linguagem de programa√ß√£o mais antiga, que √© principalmente usada para desenvolvimento de aplica√ß√µes cient√≠ficas e de engenharia.\n",
      "\n",
      "Portanto, se voc√™ est√° procurando uma linguagem de programa√ß√£o que seja f√°cil de aprender e que possa ser usada para desenvolver uma variedade de programas, eu recomendaria Python.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Sou um estudante de ensino m√©dio. Quais destas atividades voc√™ recomenda e porqu√™:\n",
    "a) Aprender Python\n",
    "b) Aprender Javascript\n",
    "c) Aprender Fortran\n",
    "\"\"\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32290ac9fb2b"
   },
   "source": [
    "### Melhore a qualidade da resposta incluindo exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "132834f5db2c"
   },
   "source": [
    "Outra maneira de melhorar a qualidade da resposta √© adicionar exemplos em seu prompt. O LLM aprende no contexto dos exemplos sobre como responder. Normalmente, um a cinco exemplos (shots) s√£o suficientes para melhorar a qualidade das respostas. Incluir muitos exemplos pode fazer com que o modelo ajuste demais os dados e reduza a qualidade das respostas.\n",
    "\n",
    "Semelhante ao treinamento de modelo cl√°ssico, a qualidade e a distribui√ß√£o dos exemplos s√£o muito importantes. Escolha exemplos representativos dos cen√°rios que voc√™ precisa que o modelo aprenda e mantenha a distribui√ß√£o dos exemplos (por exemplo, n√∫mero de exemplos por classe no caso de classifica√ß√£o) alinhada com sua distribui√ß√£o real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46520d938b6a"
   },
   "source": [
    "#### Zero-shot prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46d3b47e6cea"
   },
   "source": [
    "Abaixo est√° um exemplo de prompt zero-shot, onde voc√™ n√£o fornece nenhum exemplo para o LLM dentro do pr√≥prio prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2cbe03eb0b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decida se um Tweet apresenta um sentimento positivo, negativo ou neutro.\n",
    "\n",
    "Tweet: Eu amei os seus videos mais recentes no YouTube!\n",
    "Sentimento: \n",
    "\"\"\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0daabca1359"
   },
   "source": [
    "#### One-shot prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42c4652fc5c2"
   },
   "source": [
    "Abaixo est√° um exemplo one-shot, onde voc√™ fornece um exemplo para o LLM dentro do prompt para fornecer alguma orienta√ß√£o sobre o tipo de resposta que voc√™ deseja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cfe584860787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negativo\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decida se um Tweet apresenta um sentimento positivo, negativo ou neutro.\n",
    "\n",
    "Tweet: Eu amei os seus videos mais recentes no YouTube!\n",
    "Sentimento: positivo\n",
    "\n",
    "Tweet: Foi dif√≠cil. Super chato üò†\n",
    "Sentimento:\n",
    "\"\"\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef58c35005c0"
   },
   "source": [
    "#### Few-shot prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b630e8947b60"
   },
   "source": [
    "Abaixo est√° um exemplo de few-shot, onde voc√™ fornece um exemplo para o LLM dentro do prompt para dar alguma orienta√ß√£o sobre o tipo de resposta que voc√™ deseja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fb3ba21bbd11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decida se um Tweet apresenta um sentimento positivo, negativo ou neutro.\n",
    "\n",
    "Tweet: Eu amei os seus videos mais recentes no YouTube!\n",
    "Sentimento: positivo\n",
    "\n",
    "Tweet: Foi dif√≠cil. Super chato üò†\n",
    "Sentimento: negativo\n",
    "\n",
    "Tweet: Uma coisa me surpreendeu neste video - Ele foi realmente original. Ele n√£o foi o mesmo velho conte√∫do reciclado. Assista - voc√™ n√£o se arrepender√°.\n",
    "Sentimento:\n",
    "\"\"\"\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4023be726eb"
   },
   "source": [
    "#### Escolhendo entre os m√©todos zero-shot, one-shot ou few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d7870ff75cc"
   },
   "source": [
    "Qual t√©cnica de prompt usar depender√° exclusivamente do seu objetivo. Os prompts zero-shot s√£o mais abertos e podem fornecer respostas criativas, enquanto os prompts one-shot e few-shot ensinam o modelo a se comportar para que voc√™ possa obter respostas mais previs√≠veis que sejam consistentes com os exemplos fornecidos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_prompt_design.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "py310",
   "name": "pytorch-gpu.2-0.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m110"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
